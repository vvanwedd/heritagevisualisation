

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Heritage Visualisation Methods &mdash; Heritage-Visualisation.org</title>
  

  
  
  
  
    <link rel="canonical" href="http://www.heritage-visualisation.org/heritagevisualisationmethods.html"/>
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pixel+ Project" href="pixelplus.html" />
    <link rel="prev" title="Introduction" href="introduction.html" />
<!--<script src="_static/js/jquery.min.js"></script>-->
<script src="_static/js/bootstrap.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Didact+Gothic&display=swap&subset=cyrillic,cyrillic-ext,greek,greek-ext,latin-ext" rel="stylesheet">

  <!-- Font Awesome -->
  <!--<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css">-->
  <!-- Bootstrap core CSS -->
  <link href="_static/css/bootstrap.min.css" rel="stylesheet">
  <!-- Material Design Bootstrap -->
  <link href="_static/css/mdb.min.css" rel="stylesheet">

    <link href="_static/custom.css" rel="stylesheet" type="text/css">
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-155530128-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-155530128-1');
</script>


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #343131" >
          

          
            <a href="index.html" class="icon icon-home"> heritage-visualisation.org
          

          
            
            <img src="_static/logo2.png" class="logo" alt="Logo"/>
          
          </a>

          

          <div id="wy-nav-side-subheading">
	<p class="caption"><a href="http://www.heritage-visualisation.org/viewer">Go to pixel+ viewer</a></p>
</div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search heritage-visualisation.org" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="introduction.html">Introduction</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Heritage Visualisation Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#d-reconstruction-methods">3D Reconstruction Methods</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#passive-methods">Passive Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="#active-methods">Active Methods</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#multi-light-technology">Multi-Light Technology</a></li>
<li class="toctree-l3"><a class="reference internal" href="#infrared-photography">Infrared Photography</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multispectral-imaging">Multispectral Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#optical-coherence-tomography">Optical Coherence Tomography</a></li>
<li class="toctree-l3"><a class="reference internal" href="#phase-contrast-x-ray-imaging">Phase-Contrast X-ray Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#photogrammetry">Photogrammetry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#radiography">Radiography</a></li>
<li class="toctree-l3"><a class="reference internal" href="#raking-light-illumination">Raking Light Illumination</a></li>
<li class="toctree-l3"><a class="reference internal" href="#terahertz-imaging">Terahertz Imaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ultraviolet-photography">Ultraviolet Photography</a></li>
<li class="toctree-l3"><a class="reference internal" href="#x-ray-fluorescence">X-ray Fluorescence</a></li>
<li class="toctree-l3"><a class="reference internal" href="#x-ray-microtomography">X-ray Microtomography</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pixelplus.html">pixel+ Project</a></li>
<li class="toctree-l1"><a class="reference internal" href="pixelplusviewer.html">pixel+ Viewer</a></li>
<li class="toctree-l1"><a class="reference internal" href="technology.html">Technology</a></li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">heritage-visualisation.org</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
          <li><a href="introduction.html">Introduction</a> &raquo;</li>
        
      <li>Heritage Visualisation Methods</li>
    
    

  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="heritage-visualisation-methods">
<h1>Heritage Visualisation Methods<a class="headerlink" href="#heritage-visualisation-methods" title="Permalink to this headline">¶</a></h1>
<div class="section" id="d-reconstruction-methods">
<h2>3D Reconstruction Methods<a class="headerlink" href="#d-reconstruction-methods" title="Permalink to this headline">¶</a></h2>
<p>Plenty of methods exist to reconstruct a 3D representation of cultural artefacts. Depending on the used technology, some methods work better on objects with certain shapes and materials than others. Most of the time, these algorithms have parameters that the user should set and scanning methodologies that the user should follow carefully to obtain optimal results.
The output file type can be open or closed, widely popular or scarcely used.</p>
<p>The ideal 3D Reconstruction is a very small sized file containing all information of the object, i.e. a true virtual clone. In reality, 3D reconstructions only contain a small fraction of the information of an object. A mesh or point cloud contains information about the shape of an object’s surface, but not what’s inside. A 3D vector field, like the output of a X-ray microtomography scan, contains volume information. A 3D model can include an appearance models. The appearance of a material is caracterized by how that material interacts with light. Appearance models can vary between a single RGB color and a highly dimensional radiometric function describing how incident energy is scattered at a surface. For example, the appearance of the wings of butterflies cannot be synthetized into a single RGB color without loss of information, but require a higher dimensional scattering function.</p>
<p>In what follows in this section, we follow the taxonomy of methods for 3D shape extraction as described by</p>
<div class="section" id="passive-methods">
<h3>Passive Methods<a class="headerlink" href="#passive-methods" title="Permalink to this headline">¶</a></h3>
<div class="section" id="single-vantage-point-methods">
<h4>Single Vantage Point Methods<a class="headerlink" href="#single-vantage-point-methods" title="Permalink to this headline">¶</a></h4>
<div class="section" id="shape-from-texture">
<h5>Shape from Texture<a class="headerlink" href="#shape-from-texture" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="shape-from-occlusion">
<h5>Shape from Occlusion<a class="headerlink" href="#shape-from-occlusion" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="shape-from-defocus">
<h5>Shape from Defocus<a class="headerlink" href="#shape-from-defocus" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="shape-from-contour">
<h5>Shape from contour<a class="headerlink" href="#shape-from-contour" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="time-to-contact">
<h5>Time to Contact<a class="headerlink" href="#time-to-contact" title="Permalink to this headline">¶</a></h5>
</div>
</div>
<div class="section" id="multiple-vantage-points-methods">
<h4>Multiple Vantage Points Methods<a class="headerlink" href="#multiple-vantage-points-methods" title="Permalink to this headline">¶</a></h4>
<div class="section" id="passive-stereo">
<h5>Passive Stereo<a class="headerlink" href="#passive-stereo" title="Permalink to this headline">¶</a></h5>
<p>2 images of an object, taken at the same time but from different viewpoints. Typically the camera parameters (i.e. positions, orientations, focal lengths, radial and tangential distortion coefficients) are known, such that the position of a 3D point can be found using <a class="reference external" href="https://en.wikipedia.org/wiki/Triangulation_(computer_vision)">triangulation</a>. This process can be repeated for every matched 2D keypoint pair in both images, resulting in a (sparse) point cloud. For a more in depth understanding of stereo vision and its extensions, the reference work on this topic is <a class="reference external" href="https://www.cambridge.org/core/books/multiple-view-geometry-in-computer-vision/0B6F289C78B2B23F596CAA76D3D43F7A">Multiple View Geometry in computer vision</a>. The hardware typically consists of 2 cameras, placed in a rigid enclosure. The disparity (distance between the cameras) and camera parameters are typically chosen depending on the object to be scanned.</p>
</div>
<div class="section" id="structure-from-motion">
<h5>Structure from Motion<a class="headerlink" href="#structure-from-motion" title="Permalink to this headline">¶</a></h5>
<p>For stationary objects, SfM allows the user to scan the object by taking several photos while moving a (regular consumer) camera. Depending on the exact algorithm and assumptions, the self-calibrated algorithm only needs a couple of images to estimate the camera parameters.
The hardware typically only consists of a single camera, although sometimes a collection of lenses and a lighting setup can be used to improve the results (of next parts of the pipeline). Free and Open Source implementations include <a class="reference external" href="https://github.com/mapillary/OpenSfM">OpenSfM</a> and <a class="reference external" href="https://github.com/openMVG/openMVG">OpenMVG</a>. The result is a (sparse) point cloud and calibrated cameras. To get a dense point cloud or more detailed mesh reconstruction, Multi-View stereo libraries like <a class="reference external" href="https://github.com/cdcseacave/openMVS">OpenMVS</a> can be used. SfM is the first step of the popular software <a class="reference external" href="https://www.agisoft.com/">Agisoft Metashape</a>.</p>
</div>
<div class="section" id="shape-from-silhouettes">
<h5>Shape from Silhouettes<a class="headerlink" href="#shape-from-silhouettes" title="Permalink to this headline">¶</a></h5>
<p>Voxel carving, visual hull</p>
</div>
</div>
</div>
<div class="section" id="active-methods">
<h3>Active Methods<a class="headerlink" href="#active-methods" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id1">
<h4>Single Vantage Point Methods<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<div class="section" id="time-of-flight">
<h5>Time of Flight<a class="headerlink" href="#time-of-flight" title="Permalink to this headline">¶</a></h5>
<p>A Time of Flight camera sends out coded signals (e.g. using NIR LEDs or lasers) and detects the round trip delay to the particular point, corresponding to the point’s distance to the sensor. Typically the spatial resolution is much lower than other methods, as the sensor</p>
</div>
<div class="section" id="shape-from-shading">
<h5>Shape from Shading<a class="headerlink" href="#shape-from-shading" title="Permalink to this headline">¶</a></h5>
</div>
</div>
<div class="section" id="id2">
<h4>Multiple Vantage Points Methods<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<div class="section" id="structured-light">
<h5>Structured Light<a class="headerlink" href="#structured-light" title="Permalink to this headline">¶</a></h5>
<p>If the object to be scanned doesn’t have enough textural variation or small 3D variation, feature detection and feature matching, 2 steps in the passive stereo algorithm, might fail. By replacing one of the cameras with a projector, a series of grids (e.g. a Gray code pattern sequence) or a single grid (e.g. for non-rigid objects) can be projected onto the object. Typically the camera-projector pair is, like the camera-camera pair of passive stereo, fully calibrated, so that triangulation becomes a relatively easy problem.</p>
</div>
<div class="section" id="active-stereo">
<h5>Active Stereo<a class="headerlink" href="#active-stereo" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="photometric-stereo">
<h5>Photometric Stereo<a class="headerlink" href="#photometric-stereo" title="Permalink to this headline">¶</a></h5>
</div>
</div>
</div>
</div>
<div class="section" id="multi-light-technology">
<h2>Multi-Light Technology<a class="headerlink" href="#multi-light-technology" title="Permalink to this headline">¶</a></h2>
<p>Single-Camera Multi-Light technology is a well studied research topic. This website and the pixel+ viewer focuses on PTM, HSH RTI, RELIGHT RTI and PLD. For a more in depth overview of these types, see <span class="xref std std-ref">singlecameramultilight:Single-Camera, Multi-Light Technology</span>. Other RTI interpolation models for photo realistic relighting include Spherical Harmonics, Discrete Modal Decomposition and Deep Learning methods. From the set of multi light images directly or from the coefficients of the interpolation models, non photo realistic viewing styles have been developed to accentuate and reveal surface details. PLD follows a different approach and disentangles the shape and appearance information. The shape is modeled based on Photometric Stereo, whereas the appearance information is represented as a sparsely sampled lower dimensional BRDF. Shape and appearance modeling is studied in the fields of Computer Vision, Computer Graphics, Digital Heritage, and Optics and less relevant for heritage visualisation in Medical Imaging, Remote Sensing, Astrophysics, etc. Below is a compiled list of related material for background reading.</p>
<table class="colwidths-given docutils align-default" id="id5">
<caption><span class="caption-text">Single Camera Multi Light Background Material</span><a class="headerlink" href="#id5" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 75%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Paper</p></th>
<th class="head"><p>Keywords</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Malzbender, T., Gelb, D., &amp; Wolters, H. (2001, August). Polynomial texture maps. In Proceedings of the 28th annual conference on Computer graphics and interactive techniques (pp. 519-528).</p></td>
<td><p>PTM, RTI, Photorealistic Relighting</p></td>
</tr>
<tr class="row-odd"><td><p>Mudge, M., Malzbender, T., Chalmers, A., Scopigno, R., Davis, J., Wang, O., … &amp; Barbosa, J. (2008). Image-Based Empirical Information Acquisition, Scientific Reliability, and Long-Term Digital Preservation for the Natural Sciences and Cultural Heritage. Eurographics (Tutorials), 2(4).</p></td>
<td><p>PTM, HSH, RTI, Photorealistic Relighting</p></td>
</tr>
<tr class="row-even"><td><p>Pitard, G., Le Goïc, G., Mansouri, A., Favrelière, H., Desage, S. F., Samper, S. &amp; Pillet, M. (2017). Discrete Modal Decomposition: a new approach for the reflectance modeling and rendering of real surfaces. Machine Vision and Applications, 28(5-6), 607-621.</p></td>
<td><p>RTI, DCT, Photorealistic Relighting</p></td>
</tr>
<tr class="row-odd"><td><p>Drew, M. S., Hel-Or, Y., Malzbender, T., &amp; Hajari, N. (2012). Robust estimation of surface properties and interpolation of shadow/specularity components. Image and Vision Computing, 30(4-5), 317-331.</p></td>
<td><p>PTM, RTI, Photorealistic Relighting</p></td>
</tr>
<tr class="row-even"><td><p>Woodham, R. J. (1980). Photometric method for determining surface orientation from multiple images. Optical engineering, 19(1), 191139.</p></td>
<td><p>Photometric Stereo, Shape Modeling</p></td>
</tr>
<tr class="row-odd"><td><p>Ackermann, J., &amp; Goesele, M. (2015). A survey of photometric stereo techniques. Foundations and Trends® in Computer Graphics and Vision, 9(3-4), 149-254.</p></td>
<td><p>Photometric Stereo, Shape Modeling, Depth Integration</p></td>
</tr>
<tr class="row-even"><td><p>Hameeuw, H., Willems, G., Verbiest, F., Moreau, W., Van Lerberghe, K., &amp; Van Gool, L. (2005). Easy and cost-effective cuneiform digitizing. In The 6th International Symposium on Virtual Reality, Archaeology and Cultural Heritage (VAST 2005) (pp. 73-80). Eurographics Association.</p></td>
<td><p>PLD, Photometric Stereo, Photorealistic Relighting</p></td>
</tr>
<tr class="row-odd"><td><p>Verbiest, F., Willems, G., &amp; Van Gool, L. (2006). Image-based rendering for photo-realistic visualization. Virtual and Physical Prototyping, 1(1), 19-30.</p></td>
<td><p>PLD, Photometric Stereo, Photorealistic Relighting</p></td>
</tr>
<tr class="row-even"><td><p>Willems, G., Verbiest, F., Vergauwen, M., &amp; Van Gool, L. (2005, June). Real-time image based rendering from uncalibrated images. In Fifth International Conference on 3-D Digital Imaging and Modeling (3DIM’05) (pp. 221-228). IEEE 2005</p></td>
<td><p>PLD, Photometric stereo, Photorealistic Relighting</p></td>
</tr>
<tr class="row-odd"><td><p>Hameeuw, H., &amp; Willems, G. (2011). New visualization techniques for cuneiform texts and sealings. Akkadica, 132(2), 163-178.</p></td>
<td><p>PLD, Photometric stereo</p></td>
</tr>
<tr class="row-even"><td><p>Watteeuw, L., Vandermeulen, B., &amp; Proesmans, M. (2015). On the surface and beyond. an new approach with multispectral photometric stereo to assess illuminated manuscripts and their condition. Science and Engineering in Arts, Multispectral Imaging Heritage and Archaeology, book of abstracts, 1, 103-103.</p></td>
<td><p>PLD, Photometric Stereo, Multispectral Imaging, Photorealistic Relighting</p></td>
</tr>
<tr class="row-odd"><td><p>Van der Perre, A., Hameeuw, H., Boschloos, V., Delvaux, L., Proesmans, M., Vandermeulen, B., … &amp; Watteeuw, L. (2016). Towards a combined use of IR, UV and 3D-Imaging for the study of small inscribed and illuminated artefacts. Multispectral Imaging Lights on… Cultural Heritage and Museums!, 163-192.</p></td>
<td><p>PLD, Photometric Stereo, Multispectral Imaging, Photorealistic Relighting</p></td>
</tr>
<tr class="row-even"><td><p>Vandermeulen, B., Hameeuw, H., Watteeuw, L., Van Gool, L., &amp; Proesmans, M. (2018, April). Bridging Multi-light &amp; Multi-Spectral images to study, preserve and disseminate archival documents. In Archiving Conference (Vol. 2018, No. 1, pp. 64-69). Society for Imaging Science and Technology.</p></td>
<td><p>PLD, Photometric Stereo, Multispectral Imaging, Photorealistic Relighting</p></td>
</tr>
<tr class="row-odd"><td><p>Hameeuw, H., Vanweddingen, V., Van Gool, L., Proesmans, M., Vastenhoud, C., Van Der Perre, A., Vandermeulen, B. and Watteeuw, G. Pixel : Visualising Our Heritage. 2018. DH Benelux.</p></td>
<td><p>PLD, PTM, HSH, RTI, Photorealistic Relighting</p></td>
</tr>
<tr class="row-even"><td><p>Vanweddingen, V., Vastenhoud, C., Proesmans, M., Hameeuw, H., Vandermeulen, B., Van der Perre, A., Lemmers, F., Watteeuw, L., Van Gool, L. A Status Quaestionis and Future Solutions for Using Multi-Light Reflectance Imaging Approaches for Preserving Cultural Heritage Artifacts. Digital Heritage. Progress in Cultural Heritage: Documentation, Preservation, and Protection. EuroMed 2018. Lecture Notes in Computer Science, vol. 11197, 2018, pp. 204–211.</p></td>
<td><p>PLD, PTM, HSH, RTI, Photorealistic Relighting</p></td>
</tr>
<tr class="row-odd"><td><p>Hameeuw, H., Vanweddingen, V., Proesmans, M., Vastenhoud, C.,  Vandermeulen, B., Van der Perre, A., Watteeuw, L., Lemmers, F.,  Van Gool, L., Schroer, C., Mudge, M., Earl, G. Portable Light Domes in PIXEL+: Acquisition, Viewing, and Analysis. Digital Heritage 2018 3rd International Congress &amp; Expo (San Fransisco)</p></td>
<td><p>PLD, PTM, HSH, RTI, Photorealistic Relighting, Data Preservation</p></td>
</tr>
<tr class="row-even"><td><p>Hameeuw, H., Vanweddingen, V.,  Vandermeulen, B., Vastenhoud, C., Watteeuw, L., Lemmers, F., Van der Perre, A., Konijn, P., Van Gool, L., Proesmans, M. PIXEL+: integrating and standardizing of various interactive pixel-based imagery. SPIE Optics, Photonics and Digital Technologies for Imaging Applications VI 2020</p></td>
<td><p>PLD, PTM, HSH, RTI, RELIGHT, Photorealistic Relighting, Data Preservation</p></td>
</tr>
</tbody>
</table>
<ul>
<li><dl class="simple">
<dt>PTM/RTI:</dt><dd><ul class="simple">
<li><p>Zhang, M., &amp; Drew, M. S. (2014). Efficient robust image interpolation and surface properties using polynomial texture mapping. EURASIP Journal on Image and Video Processing, 2014(1), 25.</p></li>
<li><p>MacDonald, L. W. (2015). Realistic visualisation of cultural heritage objects (Doctoral dissertation, UCL (University College London)).</p></li>
<li><p>Ponchio, F., Corsini, M., &amp; Scopigno, R. (2018, June). A compact representation of relightable images for the web. In Proceedings of the 23rd International ACM Conference on 3D Web Technology (pp. 1-10).</p></li>
<li><p>Irina, M. C., Tinsae, G. D., Andrea, G., Ruggero, P., Alberto, J. V., &amp; Enrico, G. (2018, June). Artworks in the spotlight: characterization with a multispectral LED dome. In IOP Conference Series: Materials Science and Engineering (Vol. 364, No. 1, p. 012025). IOP Publishing.</p></li>
<li><p>Pintus, R., Giachetti, A., Pintore, G., &amp; Gobbetti, E. (2017). Guided robust matte-model fitting for accelerating multi-light reflectance processing techniques.</p></li>
<li></li>
<li><p>Peter, F., Andrea, B., Aeneas, K., &amp; Lukas, R. (2017). Enhanced RTI for gloss reproduction. Electronic Imaging, 2017(8), 66-72.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Photometric Stereo:</p>
<blockquote>
<div><ul class="simple">
<li><p>Basri, R., Jacobs, D., &amp; Kemelmacher, I. (2007). Photometric stereo with general, unknown lighting. International Journal of computer vision, 72(3), 239-257.</p></li>
</ul>
</div></blockquote>
</li>
<li><dl class="simple">
<dt>Multi-Light:</dt><dd><ul class="simple">
<li><p>Fattal, R., Agrawala, M., &amp; Rusinkiewicz, S. (2007). Multiscale shape and detail enhancement from multi-light image collections. ACM Transactions on Graphics (TOG), 26(3), 51.</p></li>
<li><p>Zheng, J., Li, Z., Rahardja, S., Yao, S., &amp; Yao, W. (2010, March). Collaborative image processing algorithm for detail refinement and enhancement via multi-light images. In 2010 IEEE International Conference on Acoustics, Speech and Signal Processing (pp. 1382-1385). IEEE.</p></li>
<li><p>Raskar, R., Tan, K. H., Feris, R., Yu, J., &amp; Turk, M. (2004). Non-photorealistic camera: depth edge detection and stylized rendering using multi-flash imaging. ACM transactions on graphics (TOG), 23(3), 679-688.</p></li>
<li><p>Cosentino, A., Stout, S., &amp; Scandurra, C. (2015). Innovative imaging techniques for examination and documentation of mural paintings and historical graffiti in the catacombs of San Giovanni, Syracuse. International Journal of Conservation Science, 6(1), 23-34.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="infrared-photography">
<h2>Infrared Photography<a class="headerlink" href="#infrared-photography" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Cosentino, Antonino. (2016). Infrared Technical Photography for Art Examination. e-Preservation Science. 13. 1-6. <a class="reference external" href="https://www.researchgate.net/publication/295086868_Infrared_Technical_Photography_for_Art_Examination">Researchgate</a></p></li>
</ul>
</div>
<div class="section" id="multispectral-imaging">
<h2>Multispectral Imaging<a class="headerlink" href="#multispectral-imaging" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>MacDonald, L.W., Vitorino, T., Picollo, M. et al. Assessment of multispectral and hyperspectral imaging systems for digitisation of a Russian icon. Herit Sci 5, 41 (2017) <a class="reference external" href="https://doi.org/10.1186/s40494-017-0154-1">doi:10.1186/s40494-017-0154-1</a></p></li>
</ul>
</div>
<div class="section" id="optical-coherence-tomography">
<h2>Optical Coherence Tomography<a class="headerlink" href="#optical-coherence-tomography" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Targowski, P. &amp; Iwanicka, M. Appl. Phys. A (2012) 106: 265. <a class="reference external" href="https://doi.org/10.1007/s00339-011-6687-3">doi: 10.1007/s00339-011-6687-3</a></p></li>
</ul>
</div>
<div class="section" id="phase-contrast-x-ray-imaging">
<h2>Phase-Contrast X-ray Imaging<a class="headerlink" href="#phase-contrast-x-ray-imaging" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Albertin, Fauzia &amp; Astolfo, Alberto &amp; Peccenini, Eva &amp; Hwu, Yeukuang &amp; Kaplan, Frederic &amp; Margaritondo, G.. (2015). Ancient administrative handwritten documents: X-ray analysis and imaging. Journal of Synchrotron Radiation. 22. <a href="#id3"><span class="problematic" id="id4">`</span></a>doi: 10.1107/S1600577515000314 &lt;<a class="reference external" href="https://doi.org/10.1107/S1600577515000314">https://doi.org/10.1107/S1600577515000314</a>&gt;_</p></li>
</ul>
</div>
<div class="section" id="photogrammetry">
<h2>Photogrammetry<a class="headerlink" href="#photogrammetry" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="radiography">
<h2>Radiography<a class="headerlink" href="#radiography" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="raking-light-illumination">
<h2>Raking Light Illumination<a class="headerlink" href="#raking-light-illumination" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="terahertz-imaging">
<h2>Terahertz Imaging<a class="headerlink" href="#terahertz-imaging" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Gillian C. Walker, John W. Bowen, Wendy Matthews, Soumali Roychowdhury, Julien Labaune, Gerard Mourou, Michel Menu, Ian Hodder, and J. Bianca Jackson, “Sub-surface terahertz imaging through uneven surfaces: visualizing Neolithic wall paintings in Çatalhöyük,” Opt. Express 21, 8126-8134 (2013) <a class="reference external" href="https://doi.org/10.1364%2FOE.21.008126">doi:10.1364/OE.21.008126</a></p></li>
<li><p>Pastorelli, G., Trafela, T., Taday, P. F., Portieri, A., Lowe, D., Fukunaga, K., &amp; Strlič, M. (2012). Characterisation of historic plastics using terahertz time-domain spectroscopy and pulsed imaging. Analytical and bioanalytical chemistry, 403(5), 1405-1414. <a class="reference external" href="https://doi.org/10.1007/s00216-012-5931-9">doi: 10.1007/s00216-012-5931-9</a></p></li>
<li><p><a class="reference external" href="https://web.archive.org/web/20130603025727/http://www.teraview.com/applications/nondestructive-testing/art.html">“Terahertz for Conservation of Paintings, Manuscripts and Artefacts”</a>. TeraView. Archived from the original on 2013-06-03.</p></li>
</ul>
</div>
<div class="section" id="ultraviolet-photography">
<h2>Ultraviolet Photography<a class="headerlink" href="#ultraviolet-photography" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="x-ray-fluorescence">
<h2>X-ray Fluorescence<a class="headerlink" href="#x-ray-fluorescence" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Beckhoff, B., Kanngießer, B., Langhoff, N., Wedell, R., &amp; Wolff, H. (Eds.). (2007). Handbook of practical X-ray fluorescence analysis. Springer Science &amp; Business Media. <a class="reference external" href="https://www.springer.com/gp/book/9783540286035">www.springer.com</a></p></li>
</ul>
</div>
<div class="section" id="x-ray-microtomography">
<h2>X-ray Microtomography<a class="headerlink" href="#x-ray-microtomography" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Hain, M., Bartl, J., &amp; Jacko, V. (2017, May). Use of X-ray microtomography and radiography in cultural heritage testing. In 2017 11th International Conference on Measurement (pp. 119-122). IEEE. <a class="reference external" href="https://doi.org/10.23919/MEASUREMENT.2017.7983550">doi: 10.23919/MEASUREMENT.2017.7983550</a></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="pixelplus.html" class="btn btn-neutral float-right" title="pixel+ Project" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="introduction.html" class="btn btn-neutral float-left" title="Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, KMKG-MRAH, KU Leuven and KBR

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
<div id="footer-images">
  <a href="http://www.kmkg-mrah.be/art-history-museum-0"><img src="_static/images/logo_ahm.png"></a>
   <a href="http://www.kuleuven.be"><img src="_static/images/logo_kuleuven.png"></a>
  <a href="http://www.kbr.be"><img src="_static/images/logo_kbr.png"></a>
  <a href="http://www.belspo.be"><img src="_static/images/logo_belspo.jpg"></a>
</div>
<script>
    $(window).on('load', function(){
   /* $( ".wy-nav-content" ).add( "div" )
                          .css({'position' : 'fixed', 'top':'0px', 'width':'100px', 'height':'100px', 'background-color':'yellow'});*/
    /*var xPosViewerLinkDiv = $(document).width() - ($('.wy-nav-content').offset().left + $('.wy-nav-content').outerWidth())+10;
   $( ".wy-nav-content" ).append('<div id="pixelplusViewerDiv" style="position:fixed;top:10px; width:200px;height:70px;z-index:10; right:'+xPosViewerLinkDiv+'px"><button onclick="window.location.href=\'http://www.heritage-visualisation.org/viewer/viewer.php\'">go to pixel+ Viewer</button></div>');                 
  });
  $(window).on('resize', function(){
  
   var xPosViewerLinkDiv = $(document).width() - ($('.wy-nav-content').offset().left + $('.wy-nav-content').outerWidth())-10;
    $("#pixelplusViewerDiv").css('right',xPosViewerLinkDiv+'px');
  });*/


  $("[aria-label='breadcrumbs navigation']").css('display', 'none');
  $(".rst-footer-buttons").css('display', 'none');
    });
$(document).ready(function() {
    $("a[href^='http']").attr('target','_blank');
});

</script>


</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-155530128-1', 'auto');
    ga('send', 'pageview');
    </script>

    
  



</body>
</html>